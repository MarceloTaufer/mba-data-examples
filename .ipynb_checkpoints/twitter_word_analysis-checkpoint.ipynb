{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TwitterSearch import *\n",
    "\n",
    "tweets = []\n",
    "\n",
    "try:\n",
    "    tso = TwitterSearchOrder() # create a TwitterSearchOrder object\n",
    "    tso.set_keywords(['innovation', 'definition', '-RT']) # let's define all words we would like to have a look for\n",
    "    tso.set_language('en') # we want to see English tweets only\n",
    "    tso.set_include_entities(False) # and don't give us all those entity information\n",
    "    tso.set_count(100)\n",
    "\n",
    "    # it's about time to create a TwitterSearch object with our secret tokens\n",
    "    ts = TwitterSearch(\n",
    "        consumer_key = 'OuqBzAbVzOaLeTsOzrdlizCxt',\n",
    "        consumer_secret = 'q3zuX2ho85CM1D1CWqDf91tb0qo8PCGOBn34ZNrQBTtJReLV8G',\n",
    "        access_token = '35594417-wbW8IerYFAnqyHqFfKdrvK0eLybTi3R5Ejtz0AJIr',\n",
    "        access_token_secret = 'wI93ddk0dPSqF2HazWV57HXg1UrKyYxbktihYe77uEQOV'\n",
    "    )\n",
    "    \n",
    "    last_id = None\n",
    "    for i in range(5):\n",
    "        for tweet in ts.search_tweets_iterable(tso):\n",
    "            tweets.append(tweet)\n",
    "            if last_id is None or tweet['id'] < last_id:\n",
    "                last_id = tweet['id']\n",
    "        tso.set_max_id(last_id - 1)\n",
    "except TwitterSearchException as e: # take care of all those ugly errors if there are some\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'created_at': 'Fri Jul 05 12:59:26 +0000 2019', 'id': 1147127849012404225, 'id_str': '1147127849012404225', 'text': '“we’ve reached a critical time when companies are being challenged to innovate new product offerings that meet the… https://t.co/1VHIRpPpU1', 'truncated': True, 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'}, 'source': '<a href=\"https://ifttt.com\" rel=\"nofollow\">IFTTT</a>', 'in_reply_to_status_id': None, 'in_reply_to_status_id_str': None, 'in_reply_to_user_id': None, 'in_reply_to_user_id_str': None, 'in_reply_to_screen_name': None, 'user': {'id': 3314059234, 'id_str': '3314059234', 'name': 'New Jersey CPCUs', 'screen_name': 'NewJerseyCPCUs', 'location': 'New Jersey, USA', 'description': 'The New Jersey CPCU Society Chapter is a community of credentialed property and casualty insurance professionals.', 'url': 'http://t.co/WMyj2NtLTe', 'entities': {'url': {'urls': [{'url': 'http://t.co/WMyj2NtLTe', 'expanded_url': 'http://newjersey.cpcusociety.org', 'display_url': 'newjersey.cpcusociety.org', 'indices': [0, 22]}]}, 'description': {'urls': []}}, 'protected': False, 'followers_count': 312, 'friends_count': 217, 'listed_count': 4, 'created_at': 'Mon Jun 08 22:20:46 +0000 2015', 'favourites_count': 1760, 'utc_offset': None, 'time_zone': None, 'geo_enabled': True, 'verified': False, 'statuses_count': 820, 'lang': None, 'contributors_enabled': False, 'is_translator': False, 'is_translation_enabled': False, 'profile_background_color': 'C0DEED', 'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png', 'profile_background_tile': False, 'profile_image_url': 'http://pbs.twimg.com/profile_images/793286115784523776/WUNt_t7m_normal.jpg', 'profile_image_url_https': 'https://pbs.twimg.com/profile_images/793286115784523776/WUNt_t7m_normal.jpg', 'profile_banner_url': 'https://pbs.twimg.com/profile_banners/3314059234/1477969142', 'profile_link_color': '1DA1F2', 'profile_sidebar_border_color': 'C0DEED', 'profile_sidebar_fill_color': 'DDEEF6', 'profile_text_color': '333333', 'profile_use_background_image': True, 'has_extended_profile': False, 'default_profile': True, 'default_profile_image': False, 'following': False, 'follow_request_sent': False, 'notifications': False, 'translator_type': 'none'}, 'geo': None, 'coordinates': None, 'place': None, 'contributors': None, 'is_quote_status': False, 'retweet_count': 1, 'favorite_count': 1, 'favorited': False, 'retweeted': False, 'possibly_sensitive': False, 'lang': 'en'}\n"
     ]
    }
   ],
   "source": [
    "print(tweets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove replies\n",
    "for tweet in tweets:\n",
    "    if tweet['in_reply_to_status_id'] or tweet['in_reply_to_user_id'] or tweet['in_reply_to_screen_name'] is not None:\n",
    "        tweets.remove(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "tweet_set = set()\n",
    "\n",
    "for tweet in tweets:\n",
    "    tweet_set.add(tweet['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    }
   ],
   "source": [
    "len(tweet_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/mojo/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_words = ['innovation', 'definition']\n",
    "\n",
    "def check_word(word):\n",
    "    if word in stop_words:\n",
    "        return False\n",
    "    if \"//\" in word:\n",
    "        return False\n",
    "    if \"http\" in word:\n",
    "        return False\n",
    "    if \"@\" in word:\n",
    "        return False\n",
    "    if word in search_words:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_count = dict()\n",
    "\n",
    "for tweet in tweet_set:\n",
    "    tokenized_words = nltk.word_tokenize(tweet)\n",
    "    tokenized_words = [word.lower() for word in tokenized_words if word.isalpha()]\n",
    "    keywords = [word for word in tokenized_words if check_word(word.lower())]\n",
    "    for keyword in keywords:\n",
    "        if keyword not in keyword_count:\n",
    "            keyword_count[keyword.lower()] = 0\n",
    "        keyword_count[keyword.lower()] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "know 18\n",
      "create 18\n",
      "culture 17\n",
      "business 19\n",
      "chatted 16\n",
      "crisbeswick 16\n",
      "learn 16\n",
      "new 11\n"
     ]
    }
   ],
   "source": [
    "for keyword in keyword_count:\n",
    "    if keyword_count[keyword] > 5:\n",
    "        print(keyword, keyword_count[keyword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
